{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb116f9",
   "metadata": {},
   "source": [
    "# Sentiment Classification on Text Data \n",
    "\n",
    "**Authors:** <br>\n",
    "Ian Colson (colso031) <br>\n",
    "Maitrayee Deka (deka0031)<br>\n",
    "Sneha Patri(patri316) <br>\n",
    "Aditi Patil (patil112) <br>\n",
    "Benjamin Swenson(swen0754) <br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ebdad",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3801779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e781a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61454</th>\n",
       "      <td>fear</td>\n",
       "      <td>Melissa stared at her friend in dism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61455</th>\n",
       "      <td>happy</td>\n",
       "      <td>Successive state elections have seen the gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61456</th>\n",
       "      <td>fear</td>\n",
       "      <td>Vincent was irritated but not dismay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61457</th>\n",
       "      <td>happy</td>\n",
       "      <td>Kendall-Hume turned back to face the dismayed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61458</th>\n",
       "      <td>happy</td>\n",
       "      <td>I am dismayed , but not surpris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61459 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               Text\n",
       "0       sadness  @tiffanylue i know  i was listenin to bad habi...\n",
       "1       sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2       sadness                Funeral ceremony...gloomy friday...\n",
       "3         happy               wants to hang out with friends SOON!\n",
       "4       neutral  @dannycastillo We want to trade with someone w...\n",
       "...         ...                                                ...\n",
       "61454      fear               Melissa stared at her friend in dism\n",
       "61455     happy  Successive state elections have seen the gover...\n",
       "61456      fear               Vincent was irritated but not dismay\n",
       "61457     happy  Kendall-Hume turned back to face the dismayed ...\n",
       "61458     happy                    I am dismayed , but not surpris\n",
       "\n",
       "[61459 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"combined_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb36402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# stopWords = stopwords.words(\"english\")\n",
    "\n",
    "# def cleanText(text):\n",
    "    \n",
    "#     output = \"\"\n",
    "    \n",
    "    \n",
    "#     for word in text.split():\n",
    "#         cleanWord = re.sub(\"[^a-zA-Z]\",  # Search for all non-letters\n",
    "#                           \" \",          # Replace all non-letters with spaces\n",
    "#                           str(word))\n",
    "#         if cleanWord in stopWords:\n",
    "#             pass\n",
    "#         else:\n",
    "#             output = output + \" \" + cleanWord\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4097b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df['Text'] = df['Text'].apply(lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",'',x))\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "650baa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>tiffanylu know listenin bad habit earlier star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed headach ughhhh waitin call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funer ceremoni gloomi friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>want hang friend SOON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>dannycastillo We want trade someon Houston tic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               Text\n",
       "0   sadness  tiffanylu know listenin bad habit earlier star...\n",
       "1   sadness            Layin n bed headach ughhhh waitin call \n",
       "2   sadness                      Funer ceremoni gloomi friday \n",
       "3     happy                             want hang friend SOON \n",
       "4   neutral  dannycastillo We want trade someon Houston tic..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import snowballstemmer\n",
    "ss = snowballstemmer.stemmer('english')\n",
    "def replace(x):\n",
    "    words = x.split()\n",
    "    newtext = ''\n",
    "    for w in words:\n",
    "        n = ss.stemWord(w)\n",
    "        newtext += n\n",
    "        newtext += \" \"\n",
    "    return newtext\n",
    "# Applying the stemmer\n",
    "df['Text'] = df['Text'].apply(lambda x: replace(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941005e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for stratifying the dataset (oversampling)\n",
    "def stratify(data, N):\n",
    "    rows = []\n",
    "    fear = data[data['sentiment'] == 'fear']\n",
    "    happy = data[data['sentiment'] == 'happy']\n",
    "    sad = data[data['sentiment'] == 'sadness']\n",
    "    neutral = data[data['sentiment'] == 'neutral']\n",
    "    love = data[data['sentiment'] == 'love']\n",
    "    anger = data[data['sentiment'] == 'anger']\n",
    "    surprise = data[data['sentiment'] == 'surprise']\n",
    "    relief = data[data['sentiment'] == 'relief']\n",
    "    \n",
    "    for i in range(N):\n",
    "        #print(fear.loc[np.random.choice(fear.index)])\n",
    "        rows.append(fear.loc[np.random.choice(fear.index)])\n",
    "        rows.append(happy.loc[np.random.choice(happy.index)])\n",
    "        rows.append(sad.loc[np.random.choice(sad.index)])\n",
    "        rows.append(neutral.loc[np.random.choice(neutral.index)])\n",
    "        rows.append(love.loc[np.random.choice(love.index)])\n",
    "        rows.append(anger.loc[np.random.choice(anger.index)])\n",
    "        rows.append(surprise.loc[np.random.choice(surprise.index)])\n",
    "        rows.append(relief.loc[np.random.choice(relief.index)])\n",
    "    sentiments = [x['sentiment'] for x in rows]\n",
    "    texts = [x['Text'] for x in rows]\n",
    "    d = {'sentiment': sentiments, 'Text': texts}\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760129a7",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebcc05aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "# Balanced_Train, Balanced_Test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], \n",
    "                                                    df['sentiment'],test_size=0.20, \n",
    "                                                    random_state=42)\n",
    "# Notice here that We are splitting the X and y components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5de9080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join test and train X and y's together to stratify\n",
    "data_train = pd.concat([X_train,y_train],axis=1)\n",
    "data_test =  pd.concat([X_test,y_test],axis=1)\n",
    "# balanced data frame with X and y\n",
    "train_balanced = stratify(data_train, 8000)\n",
    "test_balanced  = stratify(data_test, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4af8e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y vectors for balanced training set\n",
    "strat_X_train = train_balanced[\"Text\"]\n",
    "strat_y_train = train_balanced[\"sentiment\"]\n",
    "# create X and y vectors for balanced test set\n",
    "strat_X_test = test_balanced[\"Text\"]\n",
    "strat_y_test = test_balanced[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f115b76",
   "metadata": {},
   "source": [
    "### Creating a document matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d465c69",
   "metadata": {},
   "source": [
    "#### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4939bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words='english', max_features = 10000)\n",
    "# unbalanced train\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "# balanced train\n",
    "X_train_strat_counts = count_vect.fit_transform(strat_X_train)\n",
    "\n",
    "# Applying the TFidf transformer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "# unbalanced train\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# balanced train\n",
    "X_train_strat_tfidf = tfidf_transformer.fit_transform(X_train_strat_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56b43f0",
   "metadata": {},
   "source": [
    "#### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39c5e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unbalanced testset\n",
    "# count vectorizer\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "# Tfidf transformer\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "# balanced testset\n",
    "# count vectorizer\n",
    "X_test_strat_counts = count_vect.transform(strat_X_test)\n",
    "# Tfidf transformer\n",
    "X_test_strat_tfidf = tfidf_transformer.transform(X_test_strat_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4394671",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4842b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83052d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.68296184\n",
      "Iteration 2, loss = 1.36762519\n",
      "Iteration 3, loss = 1.11675966\n",
      "Iteration 4, loss = 0.76619951\n",
      "Iteration 5, loss = 0.41295419\n",
      "Iteration 6, loss = 0.23075399\n",
      "Iteration 7, loss = 0.15758900\n",
      "Iteration 8, loss = 0.12909750\n",
      "Iteration 9, loss = 0.11148262\n",
      "Iteration 10, loss = 0.10269851\n",
      "Iteration 11, loss = 0.09607873\n",
      "Iteration 12, loss = 0.09149576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owner/.local/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf1 = MLPClassifier(hidden_layer_sizes = (500, 250, 100), \n",
    "                    random_state = 1, max_iter = 12, verbose = True).fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71d4b49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.39547739\n",
      "Iteration 2, loss = 0.67241138\n",
      "Iteration 3, loss = 0.34011916\n",
      "Iteration 4, loss = 0.16898558\n",
      "Iteration 5, loss = 0.10459997\n",
      "Iteration 6, loss = 0.08066954\n",
      "Iteration 7, loss = 0.07121882\n",
      "Iteration 8, loss = 0.06626117\n",
      "Iteration 9, loss = 0.06220303\n",
      "Iteration 10, loss = 0.05936046\n",
      "Iteration 11, loss = 0.05723220\n",
      "Iteration 12, loss = 0.05596236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owner/.local/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf2 = MLPClassifier(hidden_layer_sizes = (500, 250, 100), \n",
    "                    random_state = 1, max_iter = 12, verbose = True).fit(X_train_strat_tfidf, strat_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11e2ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = clf1.predict(X_test_tfidf)\n",
    "prediction2 = clf2.predict(X_test_strat_tfidf)\n",
    "prediction3 = clf1.predict(X_test_strat_tfidf)\n",
    "prediction4 = clf2.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61c473ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewed training on skewed data:\n",
      "Accuracy score: 0.17450374227139603\n",
      "precision score: 0.12318861263240737\n",
      "recall score: 0.123142506520839\n",
      "f1 score: 0.11245959659203482\n",
      "Balanced training on balanced data:\n",
      "Accuracy score: 0.2859375\n",
      "precision score: 0.3314862641016666\n",
      "recall score: 0.28593749999999996\n",
      "f1 score: 0.27640705031199\n",
      "Skewed training on balanced data:\n",
      "Accuracy score: 0.116875\n",
      "precision score: 0.10379174849507505\n",
      "recall score: 0.11687499999999999\n",
      "f1 score: 0.09147729574522498\n",
      "Balanced training on skewed data:\n",
      "Accuracy score: 0.33444516758867554\n",
      "precision score: 0.28292758800028667\n",
      "recall score: 0.2878878663439397\n",
      "f1 score: 0.2804262859992989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Skewed training on skewed data:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, prediction1)))\n",
    "print('precision score: {}'.format(precision_score(y_test, prediction1, average='macro')))\n",
    "print('recall score: {}'.format(recall_score(y_test, prediction1,average='macro')))\n",
    "print('f1 score: {}'.format(f1_score(y_test, prediction1,average='macro')))\n",
    "print()\n",
    "print('Balanced training on balanced data:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(strat_y_test, prediction2)))\n",
    "print('precision score: {}'.format(precision_score(strat_y_test, prediction2, average='macro')))\n",
    "print('recall score: {}'.format(recall_score(strat_y_test, prediction2,average='macro')))\n",
    "print('f1 score: {}'.format(f1_score(strat_y_test, prediction2,average='macro')))\n",
    "print()\n",
    "print('Skewed training on balanced data:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(strat_y_test, prediction3)))\n",
    "print('precision score: {}'.format(precision_score(strat_y_test, prediction3, average='macro')))\n",
    "print('recall score: {}'.format(recall_score(strat_y_test, prediction3,average='macro')))\n",
    "print('f1 score: {}'.format(f1_score(strat_y_test, prediction3,average='macro')))\n",
    "print()\n",
    "print('Balanced training on skewed data:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, prediction4)))\n",
    "print('precision score: {}'.format(precision_score(y_test, prediction4, average='macro')))\n",
    "print('recall score: {}'.format(recall_score(y_test, prediction4,average='macro')))\n",
    "print('f1 score: {}'.format(f1_score(y_test, prediction4,average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66fbc3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Real world data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7d84802",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReal = pd.read_csv('realWorldEmotions.csv')\n",
    "# Removing punctuation, URL, and tags\n",
    "#dfReal[\"Text\"] = dfReal.Text.apply(lambda x: cleanText(x))\n",
    "dfReal['Text'] = dfReal['Text'].apply(lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",'',x))\n",
    "#drop na values\n",
    "dfReal.dropna(inplace=True)\n",
    "#stem the text\n",
    "dfReal['Text'] = dfReal['Text'].apply(lambda x: replace(x))\n",
    "dfReal['Sentiment'] = np.where((dfReal.Sentiment == 'joy'),'happy', dfReal.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb0d2422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to document matrix \n",
    "X = dfReal[\"Text\"]\n",
    "y = dfReal[\"Sentiment\"]\n",
    "# count vectorizer\n",
    "X_count = count_vect.transform(X)\n",
    "# Tfidf transformer\n",
    "X_tfidf = tfidf_transformer.transform(X_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba3d78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on unbalanced trained model\n",
    "prediction_real1 = clf1.predict(X_tfidf)\n",
    "# prediction on balanced trained model\n",
    "prediction_real2 = clf2.predict(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5922b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewed training model tested on real data:\n",
      "Accuracy score: 0.102\n",
      "precision score: 0.12906093868242963\n",
      "recall score: 0.0691272570982783\n",
      "f1 score: 0.07552023743386296\n",
      "Balanced training model tested on real data:\n",
      "Accuracy score: 0.5845\n",
      "precision score: 0.4746816772874069\n",
      "recall score: 0.4209097031876658\n",
      "f1 score: 0.42089144727535754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owner/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/owner/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Skewed training model tested on real data:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(y, prediction_real1)))\n",
    "print('precision score: {}'.format(precision_score(y, prediction_real1, average='macro')))\n",
    "print('recall score: {}'.format(recall_score(y, prediction_real1,average='macro')))\n",
    "print('f1 score: {}'.format(f1_score(y, prediction_real1,average='macro')))\n",
    "print()\n",
    "print('Balanced training model tested on real data:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(y, prediction_real2)))\n",
    "print('precision score: {}'.format(precision_score(y, prediction_real2, average='macro')))\n",
    "print('recall score: {}'.format(recall_score(y, prediction_real2,average='macro')))\n",
    "print('f1 score: {}'.format(f1_score(y, prediction_real2,average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505cdb95",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d44ad4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "954a5c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training on unbalanced data setÂ¶\n",
    "clf1 = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "# Training on a balanced dataset\n",
    "clf2 = MultinomialNB().fit(X_train_strat_tfidf, strat_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84748b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training all models\n",
    "prediction1 = clf1.predict(X_test_tfidf)\n",
    "prediction2 = clf2.predict(X_test_strat_tfidf)\n",
    "prediction3 = clf1.predict(X_test_strat_tfidf)\n",
    "prediction4 = clf2.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "906382ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewed training and skewed test data:\n",
      "Accuracy score: 0.1886592905955093\n",
      "precision score: 0.11808162154673298\n",
      "recall score: 0.11948078523422301\n",
      "f1 score: 0.11158782469440087\n",
      "Balanced training and balanced test data:\n",
      "Accuracy score: 0.3286875\n",
      "precision score: 0.3301422351657546\n",
      "recall score: 0.32868749999999997\n",
      "f1 score: 0.32671432287964675\n",
      "Skewed training and balanced test data:\n",
      "Accuracy score: 0.112125\n",
      "precision score: 0.09957593598076064\n",
      "recall score: 0.112125\n",
      "f1 score: 0.08317855999493357\n",
      "Balanced training and skewed test data:\n",
      "Accuracy score: 0.3159778717865278\n",
      "precision score: 0.2861906182535198\n",
      "recall score: 0.32456878272826584\n",
      "f1 score: 0.28715688025593855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Skewed training and skewed test data:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, prediction1)))\n",
    "print('precision score: {}'.format(precision_score(y_test, prediction1, average='macro')))\n",
    "print('recall score: {}'.format(recall_score(y_test, prediction1,average='macro')))\n",
    "print('f1 score: {}'.format(f1_score(y_test, prediction1,average='macro')))\n",
    "print()\n",
    "print('Balanced training and balanced test data:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(strat_y_test, prediction2)))\n",
    "print('precision score: {}'.format(precision_score(strat_y_test, prediction2, average='macro')))\n",
    "print('recall score: {}'.format(recall_score(strat_y_test, prediction2,average='macro')))\n",
    "print('f1 score: {}'.format(f1_score(strat_y_test, prediction2,average='macro')))\n",
    "print()\n",
    "print('Skewed training and balanced test data:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(strat_y_test, prediction3)))\n",
    "print('precision score: {}'.format(precision_score(strat_y_test, prediction3, average='macro')))\n",
    "print('recall score: {}'.format(recall_score(strat_y_test, prediction3,average='macro')))\n",
    "print('f1 score: {}'.format(f1_score(strat_y_test, prediction3,average='macro')))\n",
    "print()\n",
    "print('Balanced training and skewed test data:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, prediction4)))\n",
    "print('precision score: {}'.format(precision_score(y_test, prediction4, average='macro')))\n",
    "print('recall score: {}'.format(recall_score(y_test, prediction4,average='macro')))\n",
    "print('f1 score: {}'.format(f1_score(y_test, prediction4,average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0975e42",
   "metadata": {},
   "source": [
    "#### Real world data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb46e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReal = pd.read_csv('realWorldEmotions.csv')\n",
    "# Removing punctuation, URL, and tags\n",
    "#dfReal[\"Text\"] = dfReal.Text.apply(lambda x: cleanText(x))\n",
    "dfReal['Text'] = dfReal['Text'].apply(lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",'',x))\n",
    "#drop na values\n",
    "dfReal.dropna(inplace=True)\n",
    "#stem the text\n",
    "dfReal['Text'] = dfReal['Text'].apply(lambda x: replace(x))\n",
    "dfReal['Sentiment'] = np.where((dfReal.Sentiment == 'joy'),'happy', dfReal.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9967400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to document matrix \n",
    "X = dfReal[\"Text\"]\n",
    "y = dfReal[\"Sentiment\"]\n",
    "# count vectorizer\n",
    "X_count = count_vect.transform(X)\n",
    "# Tfidf transformer\n",
    "X_tfidf = tfidf_transformer.transform(X_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a342d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on unbalanced trained model\n",
    "prediction_real1 = clf1.predict(X_tfidf)\n",
    "# prediction on balanced trained model\n",
    "prediction_real2 = clf2.predict(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87ce010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewed training model tested on real data:\n",
      "Accuracy score: 0.129\n",
      "precision score: 0.1176547853561576\n",
      "recall score: 0.07866765705948009\n",
      "f1 score: 0.07965731233845391\n",
      "Balanced training model tested on real data:\n",
      "Accuracy score: 0.622\n",
      "precision score: 0.4655266905950378\n",
      "recall score: 0.4418337821229423\n",
      "f1 score: 0.4254309506683617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owner/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/owner/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Skewed training model tested on real data:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(y, prediction_real1)))\n",
    "print('precision score: {}'.format(precision_score(y, prediction_real1, average='macro')))\n",
    "print('recall score: {}'.format(recall_score(y, prediction_real1,average='macro')))\n",
    "print('f1 score: {}'.format(f1_score(y, prediction_real1,average='macro')))\n",
    "print()\n",
    "print('Balanced training model tested on real data:')\n",
    "print('Accuracy score: {}'.format(accuracy_score(y, prediction_real2)))\n",
    "print('precision score: {}'.format(precision_score(y, prediction_real2, average='macro')))\n",
    "print('recall score: {}'.format(recall_score(y, prediction_real2,average='macro')))\n",
    "print('f1 score: {}'.format(f1_score(y, prediction_real2,average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c3fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e27765ee",
   "metadata": {},
   "source": [
    "Note that the above warning is caused by the fact that there are more sentiments in our training dataset than in the real world test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c614cd",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a964a97",
   "metadata": {},
   "source": [
    "### One vs Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6856935",
   "metadata": {},
   "source": [
    "### One vs One"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
