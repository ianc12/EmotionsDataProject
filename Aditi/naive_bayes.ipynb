{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "62d47362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "77dc5d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61454</th>\n",
       "      <td>fear</td>\n",
       "      <td>Melissa stared at her friend in dism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61455</th>\n",
       "      <td>happy</td>\n",
       "      <td>Successive state elections have seen the gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61456</th>\n",
       "      <td>fear</td>\n",
       "      <td>Vincent was irritated but not dismay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61457</th>\n",
       "      <td>happy</td>\n",
       "      <td>Kendall-Hume turned back to face the dismayed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61458</th>\n",
       "      <td>happy</td>\n",
       "      <td>I am dismayed , but not surpris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61459 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               Text\n",
       "0       sadness  @tiffanylue i know  i was listenin to bad habi...\n",
       "1       sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2       sadness                Funeral ceremony...gloomy friday...\n",
       "3         happy               wants to hang out with friends SOON!\n",
       "4       neutral  @dannycastillo We want to trade with someone w...\n",
       "...         ...                                                ...\n",
       "61454      fear               Melissa stared at her friend in dism\n",
       "61455     happy  Successive state elections have seen the gover...\n",
       "61456      fear               Vincent was irritated but not dismay\n",
       "61457     happy  Kendall-Hume turned back to face the dismayed ...\n",
       "61458     happy                    I am dismayed , but not surpris\n",
       "\n",
       "[61459 rows x 2 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"combined_data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5546ca0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fear        16241\n",
       "happy       13508\n",
       "sadness      9796\n",
       "neutral      8960\n",
       "love         4720\n",
       "anger        4069\n",
       "surprise     2639\n",
       "relief       1526\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3af54bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation, URL, and tags\n",
    "import re\n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",'',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f2aa8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7a0e0d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61459, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>i know  i was listenin to bad habit earlier a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhhwaitin on y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremonygloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>wants to hang out with friends SOON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>We want to trade with someone who has Houston...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               Text\n",
       "0   sadness   i know  i was listenin to bad habit earlier a...\n",
       "1   sadness  Layin n bed with a headache  ughhhhwaitin on y...\n",
       "2   sadness                      Funeral ceremonygloomy friday\n",
       "3     happy                wants to hang out with friends SOON\n",
       "4   neutral   We want to trade with someone who has Houston..."
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2ed94bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "630493a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>i know  i was listenin to bad habit earlier a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>layin n bed with a headach  ughhhhwaitin on yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>funer ceremonygloomi friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>want to hang out with friend soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>we want to trade with someon who has houston ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61454</th>\n",
       "      <td>fear</td>\n",
       "      <td>melissa stare at her friend in dism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61455</th>\n",
       "      <td>happy</td>\n",
       "      <td>success state elect have seen the govern parti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61456</th>\n",
       "      <td>fear</td>\n",
       "      <td>vincent was irrit but not dismay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61457</th>\n",
       "      <td>happy</td>\n",
       "      <td>kendallhum turn back to face the dismay coup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61458</th>\n",
       "      <td>happy</td>\n",
       "      <td>i am dismay  but not surpri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61459 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               Text\n",
       "0       sadness   i know  i was listenin to bad habit earlier a...\n",
       "1       sadness  layin n bed with a headach  ughhhhwaitin on yo...\n",
       "2       sadness                        funer ceremonygloomi friday\n",
       "3         happy                  want to hang out with friend soon\n",
       "4       neutral   we want to trade with someon who has houston ...\n",
       "...         ...                                                ...\n",
       "61454      fear                melissa stare at her friend in dism\n",
       "61455     happy  success state elect have seen the govern parti...\n",
       "61456      fear                   vincent was irrit but not dismay\n",
       "61457     happy       kendallhum turn back to face the dismay coup\n",
       "61458     happy                        i am dismay  but not surpri\n",
       "\n",
       "[61459 rows x 2 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\") \n",
    "# Split string on each row into a list of words\n",
    "data['Text'] = data.apply(lambda x : x['Text'].split(\" \"),axis=1)\n",
    "# Apply the stemmer on each word\n",
    "data['Text'] = data['Text'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "# Join list of words into a single string for each row\n",
    "data['Text'] = data['Text'].apply(' '.join)   # join list of strings into one string for each row\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00647cb",
   "metadata": {},
   "source": [
    "#### Split Train and Test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b0566088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], \n",
    "                                                    data['sentiment'],test_size=0.20, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac313e",
   "metadata": {},
   "source": [
    "#### Word of Bags: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "01b4dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer(stop_words='english', max_features = 5000)\n",
    "\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "\n",
    "# Transform testing data and return the matrix. \n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b799a4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49167, 5000)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "213135af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaaah',\n",
       " 'aah',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abil',\n",
       " 'abit',\n",
       " 'abl',\n",
       " 'abov',\n",
       " 'absenc',\n",
       " 'absolut',\n",
       " 'abt',\n",
       " 'abus',\n",
       " 'ac',\n",
       " 'academ',\n",
       " 'academi',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessori',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'accompani',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accus',\n",
       " 'ace',\n",
       " 'ach',\n",
       " 'achiev',\n",
       " 'acid',\n",
       " 'ack',\n",
       " 'acknowledg',\n",
       " 'acoust',\n",
       " 'acquaint',\n",
       " 'acquir',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'acut',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'addict',\n",
       " 'addit',\n",
       " 'address',\n",
       " 'adjust',\n",
       " 'administr',\n",
       " 'admir',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'ador',\n",
       " 'adrenalin',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'adventur',\n",
       " 'advertis',\n",
       " 'advic',\n",
       " 'advis',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affection',\n",
       " 'affirm',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'african',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'age',\n",
       " 'agenc',\n",
       " 'agent',\n",
       " 'aggrav',\n",
       " 'aggress',\n",
       " 'agh',\n",
       " 'agit',\n",
       " 'agitat',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahaha',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhh',\n",
       " 'ahhhhhh',\n",
       " 'aid',\n",
       " 'aiden',\n",
       " 'aim',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airlin',\n",
       " 'airport',\n",
       " 'aj',\n",
       " 'aka',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alarm',\n",
       " 'albeit',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alex',\n",
       " 'ali',\n",
       " 'alic',\n",
       " 'alien',\n",
       " 'aliv',\n",
       " 'allah',\n",
       " 'allen',\n",
       " 'allerg',\n",
       " 'allergi',\n",
       " 'alli',\n",
       " 'allow',\n",
       " 'alon',\n",
       " 'alongsid',\n",
       " 'alot',\n",
       " 'alreadi',\n",
       " 'alright',\n",
       " 'alter',\n",
       " 'altern',\n",
       " 'altogeth',\n",
       " 'alway',\n",
       " 'amanda',\n",
       " 'amaz',\n",
       " 'amazon',\n",
       " 'amber',\n",
       " 'america',\n",
       " 'american',\n",
       " 'ami',\n",
       " 'amor',\n",
       " 'amp',\n",
       " 'ampamp',\n",
       " 'amsterdam',\n",
       " 'amus',\n",
       " 'analog',\n",
       " 'anatomi',\n",
       " 'andi',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'ang',\n",
       " 'angel',\n",
       " 'anger',\n",
       " 'angl',\n",
       " 'angri',\n",
       " 'angui',\n",
       " 'anguish',\n",
       " 'ani',\n",
       " 'anim',\n",
       " 'ankl',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'anniversari',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'annual',\n",
       " 'anoth',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'anthoni',\n",
       " 'anti',\n",
       " 'anticip',\n",
       " 'antsi',\n",
       " 'anxieti',\n",
       " 'anxious',\n",
       " 'anybodi',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'anytim',\n",
       " 'anywher',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apathet',\n",
       " 'apolog',\n",
       " 'apologis',\n",
       " 'app',\n",
       " 'appal',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appl',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appoint',\n",
       " 'appreci',\n",
       " 'apprehens',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approv',\n",
       " 'appt',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'archi',\n",
       " 'archuleta',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'arent',\n",
       " 'argh',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'arm',\n",
       " 'armi',\n",
       " 'arrang',\n",
       " 'arriv',\n",
       " 'ars',\n",
       " 'art',\n",
       " 'articl',\n",
       " 'articul',\n",
       " 'artist',\n",
       " 'artwork',\n",
       " 'asap',\n",
       " 'asham',\n",
       " 'ashley',\n",
       " 'asian',\n",
       " 'asid',\n",
       " 'ask',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'ass',\n",
       " 'assault',\n",
       " 'assembl',\n",
       " 'asshol',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'assum',\n",
       " 'assumpt',\n",
       " 'assur',\n",
       " 'astonish',\n",
       " 'aswel',\n",
       " 'ate',\n",
       " 'athlet',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atmospher',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attic',\n",
       " 'attitud',\n",
       " 'attract',\n",
       " 'attribut',\n",
       " 'au',\n",
       " 'audienc',\n",
       " 'audio',\n",
       " 'audit',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'aunti',\n",
       " 'aussi',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'author',\n",
       " 'auto',\n",
       " 'automat',\n",
       " 'autumn',\n",
       " 'avail',\n",
       " 'avatar',\n",
       " 'averag',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'await',\n",
       " 'awak',\n",
       " 'awar',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesom',\n",
       " 'awh',\n",
       " 'awhil',\n",
       " 'awkward',\n",
       " 'awsom',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'awwww',\n",
       " 'awwwww',\n",
       " 'ay',\n",
       " 'aye',\n",
       " 'az',\n",
       " 'babe',\n",
       " 'babi',\n",
       " 'babysit',\n",
       " 'bac',\n",
       " 'background',\n",
       " 'backpack',\n",
       " 'backup',\n",
       " 'backyard',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bagel',\n",
       " 'bah',\n",
       " 'bahaha',\n",
       " 'bail',\n",
       " 'bailey',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'balanc',\n",
       " 'balconi',\n",
       " 'bald',\n",
       " 'ball',\n",
       " 'ballet',\n",
       " 'baltimor',\n",
       " 'ban',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'bank',\n",
       " 'banquet',\n",
       " 'bar',\n",
       " 'barcelona',\n",
       " 'bare',\n",
       " 'barn',\n",
       " 'barri',\n",
       " 'base',\n",
       " 'basebal',\n",
       " 'bash',\n",
       " 'basi',\n",
       " 'basic',\n",
       " 'basket',\n",
       " 'basketbal',\n",
       " 'bass',\n",
       " 'bastard',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'batteri',\n",
       " 'battl',\n",
       " 'bay',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bbl',\n",
       " 'bbq',\n",
       " 'bc',\n",
       " 'bday',\n",
       " 'beach',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beauti',\n",
       " 'bebo',\n",
       " 'becam',\n",
       " 'becaus',\n",
       " 'becom',\n",
       " 'becuz',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'bedtim',\n",
       " 'bee',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'befor',\n",
       " 'beg',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'begun',\n",
       " 'behalf',\n",
       " 'behav',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'bein',\n",
       " 'belat',\n",
       " 'belief',\n",
       " 'believ',\n",
       " 'beliv',\n",
       " 'bell',\n",
       " 'bella',\n",
       " 'belli',\n",
       " 'belong',\n",
       " 'belov',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'benevol',\n",
       " 'benjamin',\n",
       " 'benson',\n",
       " 'berri',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'besti',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'betray',\n",
       " 'better',\n",
       " 'betti',\n",
       " 'bewi',\n",
       " 'bewild',\n",
       " 'bewilder',\n",
       " 'beyonc',\n",
       " 'bf',\n",
       " 'bff',\n",
       " 'bg',\n",
       " 'bgt',\n",
       " 'bi',\n",
       " 'bibl',\n",
       " 'bicycl',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'billi',\n",
       " 'bin',\n",
       " 'bing',\n",
       " 'bio',\n",
       " 'biolog',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitchi',\n",
       " 'bite',\n",
       " 'bitten',\n",
       " 'bitter',\n",
       " 'biz',\n",
       " 'bk',\n",
       " 'black',\n",
       " 'blackberri',\n",
       " 'blade',\n",
       " 'blah',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'bleed',\n",
       " 'bleh',\n",
       " 'blend',\n",
       " 'bless',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'blink',\n",
       " 'blip',\n",
       " 'bliss',\n",
       " 'blister',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blogger',\n",
       " 'blogtv',\n",
       " 'blond',\n",
       " 'blood',\n",
       " 'bloodi',\n",
       " 'blow',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'blur',\n",
       " 'blush',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bod',\n",
       " 'bodi',\n",
       " 'boil',\n",
       " 'bold',\n",
       " 'bolt',\n",
       " 'bomb',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'bonfir',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'bookmark',\n",
       " 'bookstor',\n",
       " 'boom',\n",
       " 'booo',\n",
       " 'boooo',\n",
       " 'booooo',\n",
       " 'boost',\n",
       " 'boot',\n",
       " 'border',\n",
       " 'bore',\n",
       " 'boredom',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bottl',\n",
       " 'bought',\n",
       " 'bounc',\n",
       " 'bounci',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'bow',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'bra',\n",
       " 'bracelet',\n",
       " 'brad',\n",
       " 'bradi',\n",
       " 'braid',\n",
       " 'brain',\n",
       " 'brake',\n",
       " 'brand',\n",
       " 'brandon',\n",
       " 'brave',\n",
       " 'brazil',\n",
       " 'brb',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breed',\n",
       " 'breez',\n",
       " 'brew',\n",
       " 'brian',\n",
       " 'brick',\n",
       " 'bridg',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brighter',\n",
       " 'brighton',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'brit',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'britney',\n",
       " 'bro',\n",
       " 'brodi',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'brooklyn',\n",
       " 'bros',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brow',\n",
       " 'brown',\n",
       " 'brows',\n",
       " 'browser',\n",
       " 'bruce',\n",
       " 'bruis',\n",
       " 'brunch',\n",
       " 'brush',\n",
       " 'bryan',\n",
       " 'bs',\n",
       " 'bt',\n",
       " 'btw',\n",
       " 'bubbl',\n",
       " 'buck',\n",
       " 'bud',\n",
       " 'buddi',\n",
       " 'budget',\n",
       " 'buffalo',\n",
       " 'bug',\n",
       " 'bugger',\n",
       " 'build',\n",
       " 'built',\n",
       " 'bull',\n",
       " 'bulli',\n",
       " 'bullshit',\n",
       " 'bum',\n",
       " 'bummer',\n",
       " 'bump',\n",
       " 'bunch',\n",
       " 'bunni',\n",
       " 'burbank',\n",
       " 'burden',\n",
       " 'burger',\n",
       " 'buri',\n",
       " 'burn',\n",
       " 'burnt',\n",
       " 'burrito',\n",
       " 'burst',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'busi',\n",
       " 'bust',\n",
       " 'butt',\n",
       " 'butter',\n",
       " 'butterfli',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buzz',\n",
       " 'bye',\n",
       " 'ca',\n",
       " 'cab',\n",
       " 'cabin',\n",
       " 'cabl',\n",
       " 'cach',\n",
       " 'cafe',\n",
       " 'caffein',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'cal',\n",
       " 'calendar',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'calm',\n",
       " 'calori',\n",
       " 'cam',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'camper',\n",
       " 'campus',\n",
       " 'canada',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candi',\n",
       " 'canuck',\n",
       " 'canva',\n",
       " 'cap',\n",
       " 'capabl',\n",
       " 'capac',\n",
       " 'cape',\n",
       " 'capit',\n",
       " 'captain',\n",
       " 'captur',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'career',\n",
       " 'carefre',\n",
       " 'careless',\n",
       " 'carolina',\n",
       " 'carpet',\n",
       " 'carri',\n",
       " 'carter',\n",
       " 'cartoon',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cast',\n",
       " 'castl',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'categori',\n",
       " 'cathol',\n",
       " 'caught',\n",
       " 'caus',\n",
       " 'cautious',\n",
       " 'cav',\n",
       " 'cd',\n",
       " 'cds',\n",
       " 'ceas',\n",
       " 'ceil',\n",
       " 'celeb',\n",
       " 'celebr',\n",
       " 'cell',\n",
       " 'cellphon',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'centr',\n",
       " 'central',\n",
       " 'centuri',\n",
       " 'cereal',\n",
       " 'ceremoni',\n",
       " 'certain',\n",
       " 'cha',\n",
       " 'chai',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'challeng',\n",
       " 'chamber',\n",
       " 'champ',\n",
       " 'champagn',\n",
       " 'champion',\n",
       " 'chanc',\n",
       " 'chang',\n",
       " 'channel',\n",
       " 'chant',\n",
       " 'chao',\n",
       " 'chapter',\n",
       " 'char',\n",
       " 'charact',\n",
       " 'charg',\n",
       " 'charger',\n",
       " 'chariti',\n",
       " 'charl',\n",
       " 'charli',\n",
       " 'charlott',\n",
       " 'charm',\n",
       " 'chase',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'cheat',\n",
       " 'check',\n",
       " 'cheek',\n",
       " 'cheer',\n",
       " 'chees',\n",
       " 'cheesecak',\n",
       " 'chef',\n",
       " 'chem',\n",
       " 'chemic',\n",
       " 'chemistri',\n",
       " 'chemo',\n",
       " 'cherish',\n",
       " 'cherri',\n",
       " 'chest',\n",
       " 'chew',\n",
       " 'chi',\n",
       " 'chica',\n",
       " 'chicago',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'childish',\n",
       " 'children',\n",
       " 'chile',\n",
       " 'chili',\n",
       " 'chill',\n",
       " 'chilli',\n",
       " 'chillin',\n",
       " 'chin',\n",
       " 'china',\n",
       " 'chines',\n",
       " 'chip',\n",
       " 'choc',\n",
       " 'chocol',\n",
       " 'choic',\n",
       " 'choir',\n",
       " 'choke',\n",
       " 'choos',\n",
       " 'chop',\n",
       " 'chore',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chris',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christin',\n",
       " 'christma',\n",
       " 'christoph',\n",
       " 'chrome',\n",
       " 'chuck',\n",
       " 'church',\n",
       " 'ci',\n",
       " 'cig',\n",
       " 'cigarett',\n",
       " 'cinema',\n",
       " 'cinnamon',\n",
       " 'circl',\n",
       " 'circumst',\n",
       " 'circus',\n",
       " 'citi',\n",
       " 'citizen',\n",
       " 'civil',\n",
       " 'claim',\n",
       " 'clair',\n",
       " 'clap',\n",
       " 'class',\n",
       " 'classi',\n",
       " 'classic',\n",
       " 'classmat',\n",
       " 'classroom',\n",
       " 'clay',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearer',\n",
       " 'clever',\n",
       " 'clich',\n",
       " 'click',\n",
       " 'client',\n",
       " 'climb',\n",
       " 'clinic',\n",
       " 'clip',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'closet',\n",
       " 'closur',\n",
       " 'cloth',\n",
       " 'cloud',\n",
       " 'cloudi',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'clutch',\n",
       " 'cmon',\n",
       " 'cn',\n",
       " 'cnt',\n",
       " 'coach',\n",
       " 'coast',\n",
       " 'coat',\n",
       " 'cobra',\n",
       " 'cock',\n",
       " 'code',\n",
       " 'coffe',\n",
       " 'coke',\n",
       " 'cold',\n",
       " 'coldplay',\n",
       " 'colin',\n",
       " 'collar',\n",
       " 'colleagu',\n",
       " 'collect',\n",
       " 'colleg',\n",
       " 'color',\n",
       " 'colorado',\n",
       " 'colour',\n",
       " 'com',\n",
       " 'combin',\n",
       " 'combo',\n",
       " 'come',\n",
       " 'comeback',\n",
       " 'comedi',\n",
       " 'comfi',\n",
       " 'comfort',\n",
       " 'comic',\n",
       " 'comin',\n",
       " 'comm',\n",
       " 'command',\n",
       " 'commenc',\n",
       " 'comment',\n",
       " 'commentari',\n",
       " 'commerci',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'communic',\n",
       " 'communiti',\n",
       " 'commut',\n",
       " 'comp',\n",
       " 'compani',\n",
       " 'companion',\n",
       " 'compar',\n",
       " 'comparison',\n",
       " 'compass',\n",
       " 'compassion',\n",
       " 'compet',\n",
       " 'competit',\n",
       " 'complac',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complet',\n",
       " 'complex',\n",
       " 'complic',\n",
       " 'compliment',\n",
       " 'compromis',\n",
       " 'comput',\n",
       " 'conan',\n",
       " 'conceal',\n",
       " 'concentr',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concert',\n",
       " 'conclus',\n",
       " 'condit',\n",
       " 'confer',\n",
       " 'confess',\n",
       " 'confid',\n",
       " 'confirm',\n",
       " 'conflict',\n",
       " 'confront',\n",
       " 'confus',\n",
       " 'congrat',\n",
       " 'congratul',\n",
       " 'connect',\n",
       " 'conquer',\n",
       " 'conscienc',\n",
       " 'conscious',\n",
       " 'consequ',\n",
       " 'conserv',\n",
       " 'consid',\n",
       " 'consider',\n",
       " 'consist',\n",
       " 'consol',\n",
       " 'constant',\n",
       " 'constitut',\n",
       " 'construct',\n",
       " 'consult',\n",
       " 'consum',\n",
       " 'cont',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'contempl',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'context',\n",
       " 'continu',\n",
       " 'contract',\n",
       " 'contrast',\n",
       " 'contribut',\n",
       " 'control',\n",
       " 'conveni',\n",
       " 'convent',\n",
       " 'convers',\n",
       " 'convert',\n",
       " 'convinc',\n",
       " 'convo',\n",
       " 'cook',\n",
       " 'cooki',\n",
       " 'cool',\n",
       " 'cooler',\n",
       " 'coolest',\n",
       " 'coop',\n",
       " 'cooper',\n",
       " 'cop',\n",
       " 'cope',\n",
       " 'copi',\n",
       " 'core',\n",
       " 'corn',\n",
       " 'corner',\n",
       " 'correct',\n",
       " 'correspond',\n",
       " 'cos',\n",
       " 'cost',\n",
       " 'costum',\n",
       " 'couch',\n",
       " 'cough',\n",
       " 'couldn',\n",
       " 'couldv',\n",
       " 'council',\n",
       " 'counsel',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'counti',\n",
       " 'countri',\n",
       " 'coupl',\n",
       " 'coupon',\n",
       " 'courag',\n",
       " 'cours',\n",
       " 'coursework',\n",
       " 'court',\n",
       " 'courtesi',\n",
       " 'courthous',\n",
       " 'cousin',\n",
       " 'cover',\n",
       " 'cow',\n",
       " 'cowork',\n",
       " 'coz',\n",
       " 'cozi',\n",
       " 'cr',\n",
       " 'crab',\n",
       " 'crack',\n",
       " 'cracker',\n",
       " 'craft',\n",
       " 'craig',\n",
       " 'cramp',\n",
       " 'crane',\n",
       " 'cranki',\n",
       " 'crap',\n",
       " 'crappi',\n",
       " 'crash',\n",
       " 'crave',\n",
       " 'crawl',\n",
       " 'crazi',\n",
       " 'cream',\n",
       " 'creat',\n",
       " 'creation',\n",
       " 'creativ',\n",
       " 'creatur',\n",
       " 'credit',\n",
       " 'creek',\n",
       " 'creep',\n",
       " 'creepi',\n",
       " 'crestfallen',\n",
       " 'crew',\n",
       " 'cri',\n",
       " 'crib',\n",
       " 'cricket',\n",
       " 'crime',\n",
       " 'cring',\n",
       " 'crisi',\n",
       " 'crisp',\n",
       " 'crispi',\n",
       " 'critic',\n",
       " 'crochet',\n",
       " 'cross',\n",
       " 'crow',\n",
       " 'crowd',\n",
       " 'crown',\n",
       " 'cruel',\n",
       " 'cruis',\n",
       " 'crumbl',\n",
       " 'crunch',\n",
       " 'crush',\n",
       " 'crutch',\n",
       " 'cryin',\n",
       " 'crystal',\n",
       " 'cs',\n",
       " 'ct',\n",
       " 'cub',\n",
       " ...]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec38c1",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9443b009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c940f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = naive_bayes.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d4103f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.3661731207289294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fe0c17",
   "metadata": {},
   "source": [
    "### Attempt to tune hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "38a90e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "print(naive_bayes.get_params())\n",
    "parameters = {\n",
    "    'alpha': np.linspace(0.001,1.5,26),\n",
    "    'fit_prior' : [True,False]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e1878306",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32713832875564985\n",
      "{'alpha': 0.3008, 'fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "scores = [\"precision\", \"recall\"]\n",
    "for score in scores:\n",
    "    clf = GridSearchCV(MultinomialNB(),parameters, scoring=\"%s_macro\" % score)\n",
    "    clf.fit(training_data,y_train)\n",
    "#     clf.predict(testing_data)\n",
    "    y_true, y_pred = y_test, clf.predict(testing_data)\n",
    "    report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "    pd.DataFrame(report_dict)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "95f87329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.3128864301985031\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naive_bayes = MultinomialNB(alpha = 0.54064,fit_prior = False )\n",
    "naive_bayes.fit(training_data,y_train)\n",
    "predictions = naive_bayes.predict(testing_data)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
