{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d47362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77dc5d00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61454</th>\n",
       "      <td>fear</td>\n",
       "      <td>Melissa stared at her friend in dism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61455</th>\n",
       "      <td>happy</td>\n",
       "      <td>Successive state elections have seen the gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61456</th>\n",
       "      <td>fear</td>\n",
       "      <td>Vincent was irritated but not dismay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61457</th>\n",
       "      <td>happy</td>\n",
       "      <td>Kendall-Hume turned back to face the dismayed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61458</th>\n",
       "      <td>happy</td>\n",
       "      <td>I am dismayed , but not surpris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               Text\n",
       "0       sadness  @tiffanylue i know  i was listenin to bad habi...\n",
       "1       sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2       sadness                Funeral ceremony...gloomy friday...\n",
       "3         happy               wants to hang out with friends SOON!\n",
       "4       neutral  @dannycastillo We want to trade with someone w...\n",
       "...         ...                                                ...\n",
       "61454      fear               Melissa stared at her friend in dism\n",
       "61455     happy  Successive state elections have seen the gover...\n",
       "61456      fear               Vincent was irritated but not dismay\n",
       "61457     happy  Kendall-Hume turned back to face the dismayed ...\n",
       "61458     happy                    I am dismayed , but not surpris\n",
       "\n",
       "[61459 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"combined_data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5546ca0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fear        16241\n",
       "happy       13508\n",
       "sadness      9796\n",
       "neutral      8960\n",
       "love         4720\n",
       "anger        4069\n",
       "surprise     2639\n",
       "relief       1526\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af54bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation, URL, and tags\n",
    "import re\n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",'',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2aa8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0e0d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61459, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>i know  i was listenin to bad habit earlier a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhhwaitin on y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremonygloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>wants to hang out with friends SOON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>We want to trade with someone who has Houston...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               Text\n",
       "0   sadness   i know  i was listenin to bad habit earlier a...\n",
       "1   sadness  Layin n bed with a headache  ughhhhwaitin on y...\n",
       "2   sadness                      Funeral ceremonygloomy friday\n",
       "3     happy                wants to hang out with friends SOON\n",
       "4   neutral   We want to trade with someone who has Houston..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ed94bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630493a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>i know  i was listenin to bad habit earlier a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>layin n bed with a headach  ughhhhwaitin on yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>funer ceremonygloomi friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>want to hang out with friend soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>we want to trade with someon who has houston ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61454</th>\n",
       "      <td>fear</td>\n",
       "      <td>melissa stare at her friend in dism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61455</th>\n",
       "      <td>happy</td>\n",
       "      <td>success state elect have seen the govern parti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61456</th>\n",
       "      <td>fear</td>\n",
       "      <td>vincent was irrit but not dismay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61457</th>\n",
       "      <td>happy</td>\n",
       "      <td>kendallhum turn back to face the dismay coup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61458</th>\n",
       "      <td>happy</td>\n",
       "      <td>i am dismay  but not surpri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               Text\n",
       "0       sadness   i know  i was listenin to bad habit earlier a...\n",
       "1       sadness  layin n bed with a headach  ughhhhwaitin on yo...\n",
       "2       sadness                        funer ceremonygloomi friday\n",
       "3         happy                  want to hang out with friend soon\n",
       "4       neutral   we want to trade with someon who has houston ...\n",
       "...         ...                                                ...\n",
       "61454      fear                melissa stare at her friend in dism\n",
       "61455     happy  success state elect have seen the govern parti...\n",
       "61456      fear                   vincent was irrit but not dismay\n",
       "61457     happy       kendallhum turn back to face the dismay coup\n",
       "61458     happy                        i am dismay  but not surpri\n",
       "\n",
       "[61459 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\") \n",
    "# Split string on each row into a list of words\n",
    "data['Text'] = data.apply(lambda x : x['Text'].split(\" \"),axis=1)\n",
    "# Apply the stemmer on each word\n",
    "data['Text'] = data['Text'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "# Join list of words into a single string for each row\n",
    "data['Text'] = data['Text'].apply(' '.join)   # join list of strings into one string for each row\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build new non-skewed dataset\n",
    "\n",
    "#sample with replacement\n",
    "def stratify(data, N):\n",
    "    rows = []\n",
    "    fear = data[data['sentiment'] == 'fear']\n",
    "    happy = data[data['sentiment'] == 'happy']\n",
    "    sad = data[data['sentiment'] == 'sadness']\n",
    "    neutral = data[data['sentiment'] == 'neutral']\n",
    "    love = data[data['sentiment'] == 'love']\n",
    "    anger = data[data['sentiment'] == 'anger']\n",
    "    surprise = data[data['sentiment'] == 'surprise']\n",
    "    relief = data[data['sentiment'] == 'relief']\n",
    "    \n",
    "    for i in range(N):\n",
    "        #print(fear.loc[np.random.choice(fear.index)])\n",
    "        rows.append(fear.loc[np.random.choice(fear.index)])\n",
    "        rows.append(happy.loc[np.random.choice(happy.index)])\n",
    "        rows.append(sad.loc[np.random.choice(sad.index)])\n",
    "        rows.append(neutral.loc[np.random.choice(neutral.index)])\n",
    "        rows.append(love.loc[np.random.choice(love.index)])\n",
    "        rows.append(anger.loc[np.random.choice(anger.index)])\n",
    "        rows.append(surprise.loc[np.random.choice(surprise.index)])\n",
    "        rows.append(relief.loc[np.random.choice(relief.index)])\n",
    "    sentiments = [x['sentiment'] for x in rows]\n",
    "    texts = [x['Text'] for x in rows]\n",
    "    d = {'sentiment': sentiments, 'Text': texts}\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stratify(data, 10000)\n",
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00647cb",
   "metadata": {},
   "source": [
    "#### Split Train and Test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0566088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], \n",
    "                                                    data['sentiment'],test_size=0.20, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac313e",
   "metadata": {},
   "source": [
    "#### Word of Bags: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b4dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# # Instantiate the CountVectorizer method\n",
    "# tf_idf = TfidfVectorizer(stop_words='english',max_features=5000, min_df = 10, max_df = 0.1)\n",
    "# tf_idf.fit(data['Text'])\n",
    "# # Fit the training data and then return the matrix\n",
    "# training_data = tf_idf.transform(X_train)\n",
    "# # Transform testing data and return the matrix. \n",
    "# testing_data = tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b799a4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49167, 3917)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "213135af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandon',\n",
       " 'abil',\n",
       " 'abit',\n",
       " 'abl',\n",
       " 'abov',\n",
       " 'absolut',\n",
       " 'abt',\n",
       " 'abus',\n",
       " 'ac',\n",
       " 'academ',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'accompani',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accus',\n",
       " 'ace',\n",
       " 'ach',\n",
       " 'achiev',\n",
       " 'acknowledg',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'addict',\n",
       " 'addit',\n",
       " 'address',\n",
       " 'adjust',\n",
       " 'admir',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'ador',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'adventur',\n",
       " 'advertis',\n",
       " 'advic',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affection',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'african',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'age',\n",
       " 'agent',\n",
       " 'aggrav',\n",
       " 'aggress',\n",
       " 'agit',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahaha',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhh',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'aka',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alarm',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alex',\n",
       " 'ali',\n",
       " 'alic',\n",
       " 'alien',\n",
       " 'aliv',\n",
       " 'allen',\n",
       " 'allergi',\n",
       " 'allow',\n",
       " 'alon',\n",
       " 'alot',\n",
       " 'alreadi',\n",
       " 'alright',\n",
       " 'altern',\n",
       " 'altogeth',\n",
       " 'alway',\n",
       " 'amaz',\n",
       " 'amazon',\n",
       " 'amber',\n",
       " 'america',\n",
       " 'american',\n",
       " 'ami',\n",
       " 'amor',\n",
       " 'amp',\n",
       " 'ampamp',\n",
       " 'amus',\n",
       " 'anatomi',\n",
       " 'andi',\n",
       " 'andrew',\n",
       " 'ang',\n",
       " 'angel',\n",
       " 'anger',\n",
       " 'angl',\n",
       " 'angri',\n",
       " 'anguish',\n",
       " 'ani',\n",
       " 'anim',\n",
       " 'ankl',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'anniversari',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'annual',\n",
       " 'anoth',\n",
       " 'answer',\n",
       " 'anthoni',\n",
       " 'anti',\n",
       " 'anticip',\n",
       " 'anxieti',\n",
       " 'anxious',\n",
       " 'anybodi',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'anytim',\n",
       " 'anywher',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apolog',\n",
       " 'app',\n",
       " 'appal',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appl',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appoint',\n",
       " 'appreci',\n",
       " 'apprehens',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approv',\n",
       " 'appt',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'arent',\n",
       " 'argh',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'arm',\n",
       " 'armi',\n",
       " 'arrang',\n",
       " 'arriv',\n",
       " 'art',\n",
       " 'articl',\n",
       " 'artist',\n",
       " 'asap',\n",
       " 'asham',\n",
       " 'ashley',\n",
       " 'asian',\n",
       " 'asid',\n",
       " 'ask',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'ass',\n",
       " 'assault',\n",
       " 'assembl',\n",
       " 'asshol',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'assum',\n",
       " 'assur',\n",
       " 'astonish',\n",
       " 'aswel',\n",
       " 'ate',\n",
       " 'athlet',\n",
       " 'atl',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atmospher',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attic',\n",
       " 'attitud',\n",
       " 'attract',\n",
       " 'audienc',\n",
       " 'audio',\n",
       " 'audit',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'aunti',\n",
       " 'aussi',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'author',\n",
       " 'auto',\n",
       " 'automat',\n",
       " 'avail',\n",
       " 'avatar',\n",
       " 'averag',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'await',\n",
       " 'awak',\n",
       " 'awar',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesom',\n",
       " 'awh',\n",
       " 'awhil',\n",
       " 'awkward',\n",
       " 'awsom',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'awwww',\n",
       " 'awwwww',\n",
       " 'aye',\n",
       " 'babe',\n",
       " 'babi',\n",
       " 'babysit',\n",
       " 'background',\n",
       " 'backup',\n",
       " 'backyard',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bah',\n",
       " 'bahaha',\n",
       " 'bake',\n",
       " 'balanc',\n",
       " 'ball',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'bare',\n",
       " 'base',\n",
       " 'basebal',\n",
       " 'bash',\n",
       " 'basi',\n",
       " 'basic',\n",
       " 'bastard',\n",
       " 'bat',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batteri',\n",
       " 'battl',\n",
       " 'bay',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bbq',\n",
       " 'bc',\n",
       " 'bday',\n",
       " 'bea',\n",
       " 'beach',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beauti',\n",
       " 'becam',\n",
       " 'becaus',\n",
       " 'becom',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'bedtim',\n",
       " 'bee',\n",
       " 'beer',\n",
       " 'befor',\n",
       " 'beg',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'begun',\n",
       " 'behav',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'bein',\n",
       " 'belief',\n",
       " 'believ',\n",
       " 'bell',\n",
       " 'bella',\n",
       " 'belli',\n",
       " 'belong',\n",
       " 'belov',\n",
       " 'ben',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'benevol',\n",
       " 'benson',\n",
       " 'berri',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'besti',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'betray',\n",
       " 'better',\n",
       " 'betti',\n",
       " 'bewild',\n",
       " 'bewilder',\n",
       " 'bf',\n",
       " 'bff',\n",
       " 'bgt',\n",
       " 'bibl',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'billi',\n",
       " 'bin',\n",
       " 'bing',\n",
       " 'bio',\n",
       " 'biolog',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitchi',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'bk',\n",
       " 'black',\n",
       " 'blackberri',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'bleed',\n",
       " 'bleh',\n",
       " 'blend',\n",
       " 'bless',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'blink',\n",
       " 'blip',\n",
       " 'bliss',\n",
       " 'blister',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blogger',\n",
       " 'blond',\n",
       " 'blood',\n",
       " 'bloodi',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'blur',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bodi',\n",
       " 'boil',\n",
       " 'bold',\n",
       " 'bomb',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'bookmark',\n",
       " 'booo',\n",
       " 'boost',\n",
       " 'boot',\n",
       " 'border',\n",
       " 'bore',\n",
       " 'boredom',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bottl',\n",
       " 'bought',\n",
       " 'bounc',\n",
       " 'bounci',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'bow',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'bracelet',\n",
       " 'brad',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'brave',\n",
       " 'brazil',\n",
       " 'brb',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breed',\n",
       " 'breez',\n",
       " 'brew',\n",
       " 'brian',\n",
       " 'bride',\n",
       " 'bridg',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brighter',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'britney',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'brooklyn',\n",
       " 'bros',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brows',\n",
       " 'browser',\n",
       " 'bruce',\n",
       " 'bruis',\n",
       " 'brunch',\n",
       " 'brush',\n",
       " 'bs',\n",
       " 'bt',\n",
       " 'btw',\n",
       " 'bubbl',\n",
       " 'buck',\n",
       " 'bud',\n",
       " 'buddi',\n",
       " 'budget',\n",
       " 'bug',\n",
       " 'bugger',\n",
       " 'build',\n",
       " 'built',\n",
       " 'bull',\n",
       " 'bulli',\n",
       " 'bullshit',\n",
       " 'bum',\n",
       " 'bummer',\n",
       " 'bump',\n",
       " 'bunch',\n",
       " 'bunni',\n",
       " 'burden',\n",
       " 'burger',\n",
       " 'buri',\n",
       " 'burn',\n",
       " 'burnt',\n",
       " 'burrito',\n",
       " 'burst',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'busi',\n",
       " 'bust',\n",
       " 'butt',\n",
       " 'butter',\n",
       " 'butterfli',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buzz',\n",
       " 'bye',\n",
       " 'ca',\n",
       " 'cab',\n",
       " 'cabl',\n",
       " 'cafe',\n",
       " 'caffein',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'calm',\n",
       " 'calori',\n",
       " 'cam',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'campus',\n",
       " 'canada',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candi',\n",
       " 'canuck',\n",
       " 'canva',\n",
       " 'cap',\n",
       " 'capabl',\n",
       " 'capac',\n",
       " 'capit',\n",
       " 'captain',\n",
       " 'captur',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'career',\n",
       " 'carefre',\n",
       " 'carri',\n",
       " 'carter',\n",
       " 'cartoon',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cast',\n",
       " 'castl',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'categori',\n",
       " 'caught',\n",
       " 'caus',\n",
       " 'cav',\n",
       " 'cd',\n",
       " 'cds',\n",
       " 'celeb',\n",
       " 'celebr',\n",
       " 'cell',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'centr',\n",
       " 'central',\n",
       " 'centuri',\n",
       " 'cereal',\n",
       " 'certain',\n",
       " 'cha',\n",
       " 'chai',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'challeng',\n",
       " 'chamber',\n",
       " 'champion',\n",
       " 'chanc',\n",
       " 'chang',\n",
       " 'channel',\n",
       " 'chapter',\n",
       " 'char',\n",
       " 'charact',\n",
       " 'charg',\n",
       " 'charger',\n",
       " 'chariti',\n",
       " 'charl',\n",
       " 'charli',\n",
       " 'charm',\n",
       " 'chase',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'cheat',\n",
       " 'check',\n",
       " 'cheek',\n",
       " 'cheer',\n",
       " 'chees',\n",
       " 'cheesecak',\n",
       " 'chem',\n",
       " 'chemistri',\n",
       " 'cherish',\n",
       " 'cherri',\n",
       " 'chest',\n",
       " 'chew',\n",
       " 'chi',\n",
       " 'chicago',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'chili',\n",
       " 'chill',\n",
       " 'chilli',\n",
       " 'chillin',\n",
       " 'chin',\n",
       " 'china',\n",
       " 'chines',\n",
       " 'chip',\n",
       " 'chocol',\n",
       " 'choic',\n",
       " 'choir',\n",
       " 'choke',\n",
       " 'choos',\n",
       " 'chop',\n",
       " 'chore',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chris',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christma',\n",
       " 'chuck',\n",
       " 'church',\n",
       " 'cigarett',\n",
       " 'cinema',\n",
       " 'circl',\n",
       " 'circumst',\n",
       " 'citi',\n",
       " 'citizen',\n",
       " 'claim',\n",
       " 'clair',\n",
       " 'clap',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classmat',\n",
       " 'classroom',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clever',\n",
       " 'click',\n",
       " 'client',\n",
       " 'climb',\n",
       " 'clinic',\n",
       " 'clip',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'closet',\n",
       " 'closur',\n",
       " 'cloth',\n",
       " 'cloud',\n",
       " 'cloudi',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'cnt',\n",
       " 'coach',\n",
       " 'coast',\n",
       " 'coat',\n",
       " 'code',\n",
       " 'coffe',\n",
       " 'coke',\n",
       " 'cold',\n",
       " 'colleagu',\n",
       " 'collect',\n",
       " 'colleg',\n",
       " 'color',\n",
       " 'colour',\n",
       " 'com',\n",
       " 'combin',\n",
       " 'combo',\n",
       " 'come',\n",
       " 'comedi',\n",
       " 'comfi',\n",
       " 'comfort',\n",
       " 'comic',\n",
       " 'comin',\n",
       " 'command',\n",
       " 'comment',\n",
       " 'commerci',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'communic',\n",
       " 'communiti',\n",
       " 'commut',\n",
       " 'comp',\n",
       " 'compani',\n",
       " 'companion',\n",
       " 'compar',\n",
       " 'comparison',\n",
       " 'compass',\n",
       " 'compassion',\n",
       " 'competit',\n",
       " 'complac',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complet',\n",
       " 'complex',\n",
       " 'complic',\n",
       " 'compliment',\n",
       " 'compromis',\n",
       " 'comput',\n",
       " 'concentr',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concert',\n",
       " 'conclus',\n",
       " 'condit',\n",
       " 'confer',\n",
       " 'confess',\n",
       " 'confid',\n",
       " 'confirm',\n",
       " 'conflict',\n",
       " 'confus',\n",
       " 'congrat',\n",
       " 'congratul',\n",
       " 'connect',\n",
       " 'conscious',\n",
       " 'consequ',\n",
       " 'conserv',\n",
       " 'consid',\n",
       " 'consider',\n",
       " 'consist',\n",
       " 'consol',\n",
       " 'constant',\n",
       " 'construct',\n",
       " 'consult',\n",
       " 'consum',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'contempl',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'context',\n",
       " 'continu',\n",
       " 'contract',\n",
       " 'contribut',\n",
       " 'control',\n",
       " 'conveni',\n",
       " 'convent',\n",
       " 'convers',\n",
       " 'convert',\n",
       " 'convinc',\n",
       " 'convo',\n",
       " 'cook',\n",
       " 'cooki',\n",
       " 'cool',\n",
       " 'cooler',\n",
       " 'cooper',\n",
       " 'cop',\n",
       " 'cope',\n",
       " 'copi',\n",
       " 'core',\n",
       " 'corn',\n",
       " 'corner',\n",
       " 'correct',\n",
       " 'cos',\n",
       " 'cost',\n",
       " 'costum',\n",
       " 'couch',\n",
       " 'cough',\n",
       " 'couldn',\n",
       " 'couldv',\n",
       " 'counsel',\n",
       " 'count',\n",
       " 'counti',\n",
       " 'countri',\n",
       " 'coupl',\n",
       " 'courag',\n",
       " 'cours',\n",
       " 'court',\n",
       " 'cousin',\n",
       " 'cover',\n",
       " 'cow',\n",
       " 'cowork',\n",
       " 'coz',\n",
       " 'crab',\n",
       " 'crack',\n",
       " 'craft',\n",
       " 'cramp',\n",
       " 'cranki',\n",
       " 'crap',\n",
       " 'crappi',\n",
       " 'crash',\n",
       " 'crave',\n",
       " 'crawl',\n",
       " 'crazi',\n",
       " 'cream',\n",
       " 'creat',\n",
       " 'creativ',\n",
       " 'creatur',\n",
       " 'credit',\n",
       " 'creep',\n",
       " 'creepi',\n",
       " 'crew',\n",
       " 'cri',\n",
       " 'crime',\n",
       " 'crisi',\n",
       " 'critic',\n",
       " 'crochet',\n",
       " 'cross',\n",
       " 'crow',\n",
       " 'crowd',\n",
       " 'crown',\n",
       " 'cruel',\n",
       " 'cruis',\n",
       " 'crunch',\n",
       " 'crush',\n",
       " 'cryin',\n",
       " 'cs',\n",
       " 'cub',\n",
       " 'cube',\n",
       " 'cuddl',\n",
       " 'cultur',\n",
       " 'cup',\n",
       " 'cupcak',\n",
       " 'cuppa',\n",
       " 'cure',\n",
       " 'curious',\n",
       " 'curl',\n",
       " 'current',\n",
       " 'curs',\n",
       " 'curtain',\n",
       " 'curv',\n",
       " 'custom',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cutest',\n",
       " 'cuti',\n",
       " 'cuz',\n",
       " 'cycl',\n",
       " 'cyrus',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'daddi',\n",
       " 'daili',\n",
       " 'daisi',\n",
       " 'dalla',\n",
       " 'dam',\n",
       " 'damag',\n",
       " 'dammit',\n",
       " 'damn',\n",
       " 'damnit',\n",
       " 'dan',\n",
       " 'danc',\n",
       " 'dancer',\n",
       " 'dang',\n",
       " 'danger',\n",
       " 'daniel',\n",
       " 'danni',\n",
       " 'dare',\n",
       " 'dark',\n",
       " 'darl',\n",
       " 'darn',\n",
       " 'dat',\n",
       " 'data',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'dave',\n",
       " 'david',\n",
       " 'dawn',\n",
       " 'day',\n",
       " 'dayi',\n",
       " 'daze',\n",
       " 'dc',\n",
       " 'dd',\n",
       " 'dead',\n",
       " 'deadlin',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'debat',\n",
       " 'decemb',\n",
       " 'decent',\n",
       " 'decid',\n",
       " 'decis',\n",
       " 'deck',\n",
       " 'declar',\n",
       " 'declin',\n",
       " 'decor',\n",
       " 'dedic',\n",
       " 'deep',\n",
       " 'deeper',\n",
       " 'deepli',\n",
       " 'def',\n",
       " 'default',\n",
       " 'defeat',\n",
       " 'defect',\n",
       " 'defend',\n",
       " 'defens',\n",
       " 'defin',\n",
       " 'definit',\n",
       " 'degre',\n",
       " 'deject',\n",
       " 'delay',\n",
       " 'delet',\n",
       " 'delic',\n",
       " 'delici',\n",
       " 'delight',\n",
       " 'deliv',\n",
       " 'deliveri',\n",
       " 'demand',\n",
       " 'demi',\n",
       " 'demo',\n",
       " 'demon',\n",
       " 'deni',\n",
       " 'dentist',\n",
       " 'denver',\n",
       " 'depart',\n",
       " 'depend',\n",
       " 'depress',\n",
       " 'depriv',\n",
       " 'depth',\n",
       " 'derbi',\n",
       " 'describ',\n",
       " 'descript',\n",
       " 'deserv',\n",
       " 'design',\n",
       " 'desir',\n",
       " 'desk',\n",
       " 'desktop',\n",
       " 'desol',\n",
       " 'despai',\n",
       " 'despair',\n",
       " 'desper',\n",
       " 'despis',\n",
       " 'despit',\n",
       " 'despond',\n",
       " 'dessert',\n",
       " 'destroy',\n",
       " 'determin',\n",
       " 'devast',\n",
       " 'develop',\n",
       " 'devic',\n",
       " 'devil',\n",
       " 'devon',\n",
       " 'devot',\n",
       " 'dew',\n",
       " 'dh',\n",
       " 'di',\n",
       " 'dia',\n",
       " 'diamond',\n",
       " 'dick',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'diego',\n",
       " 'diet',\n",
       " 'diff',\n",
       " 'differ',\n",
       " 'difficult',\n",
       " 'difficulti',\n",
       " 'dig',\n",
       " 'digit',\n",
       " 'din',\n",
       " 'dine',\n",
       " 'dinner',\n",
       " 'dip',\n",
       " 'direct',\n",
       " 'director',\n",
       " 'dirti',\n",
       " 'dis',\n",
       " 'disabl',\n",
       " 'disadvantag',\n",
       " 'disagre',\n",
       " 'disappear',\n",
       " 'disappoint',\n",
       " 'disconnect',\n",
       " 'disconsol',\n",
       " 'discont',\n",
       " 'discount',\n",
       " 'discourag',\n",
       " 'discov',\n",
       " 'discoveri',\n",
       " 'discuss',\n",
       " 'diseas',\n",
       " 'disgust',\n",
       " 'dish',\n",
       " 'dishearten',\n",
       " 'disillus',\n",
       " 'dislik',\n",
       " 'dismay',\n",
       " 'disney',\n",
       " 'disord',\n",
       " 'display',\n",
       " 'disquiet',\n",
       " 'disrespect',\n",
       " 'dissatisfi',\n",
       " 'distanc',\n",
       " 'distant',\n",
       " 'distinct',\n",
       " 'distract',\n",
       " 'distraught',\n",
       " 'distress',\n",
       " 'disturb',\n",
       " 'divin',\n",
       " 'divorc',\n",
       " 'dizzi',\n",
       " 'dj',\n",
       " 'dm',\n",
       " 'dnt',\n",
       " 'doc',\n",
       " 'doctor',\n",
       " 'document',\n",
       " 'doe',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'dog',\n",
       " 'doggi',\n",
       " 'doin',\n",
       " 'doll',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count_vector.get_feature_names()\n",
    "tf_idf.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec38c1",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9443b009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.3651155222909209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data,y_train)\n",
    "predictions = naive_bayes.predict(testing_data)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
